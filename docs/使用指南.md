# 使用指南

## 快速开始

### 1. 准备数据

将你的搜索词数据放入 `input/` 目录，支持以下格式：
- Excel文件 (.xlsx)
- CSV文件 (.csv)

**数据格式要求**：
- 必须包含 `关键词/营销要点/知识问答` 列
- 必须包含 `搜索词` 列
- 可选包含 `账户添加状态` 列

**示例数据**：
| 关键词/营销要点/知识问答 | 搜索词 | 账户添加状态 |
|------------------------|--------|-------------|
| 电影推荐 | 好看的电影 | 未添加 |
| 游戏攻略 | 游戏技巧 | 已添加 |

### 2. 选择运行模式

根据你的需求和硬件配置选择合适的运行模式：

#### 安全模式（推荐新手）
```bash
python run_safe.py
```
- 自动检查系统资源
- 自动选择最优配置
- 适合首次使用

#### 超安全模式（解决内存问题）
```bash
python run_ultra_safe.py
```
- 强制内存清理
- 极低内存配置
- 适合不稳定环境

#### CPU模式（最稳定）
```bash
python main_cpu.py
```
- 完全避免GPU问题
- 使用系统内存
- 适合小内存设备

#### 批处理模式（大数据量）
```bash
python main_auto_batch.py
```
- 自动分批处理
- 支持断点续传
- 适合处理大量数据

### 3. 查看结果

程序运行完成后，结果文件保存在 `output/analysis/YYYYMMDD/` 目录中，文件名格式为：
```
final_auto_merged_YYYYMMDD_HHMM_with_relation.xlsx
```

## 详细使用说明

### 配置文件设置

编辑 `config.py` 文件来自定义配置：

```python
class Config:
    # 模型路径
    MODEL_PATH = './models/text2vec-bge-large-chinese'
    
    # 设备选择
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # 处理参数
    BATCH_SIZE = 32          # 批次大小
    MAX_LENGTH = 128         # 最大文本长度
    
    # 路径配置
    INPUT_DIR = './input'
    OUTPUT_DIR = './output'
    CACHE_DIR = './cache'
```

### 环境变量配置

你也可以通过环境变量来配置：

```bash
# Windows
set MODEL_PATH=D:\models\text2vec-bge-large-chinese
set BATCH_SIZE=16
set DEVICE=cpu

# macOS/Linux
export MODEL_PATH="/path/to/models/text2vec-bge-large-chinese"
export BATCH_SIZE=16
export DEVICE=cpu
```

### 自定义相似度阈值

在 `analyze_similarity_result.py` 中可以调整相似度判断标准：

```python
def judge_relation(sim):
    if pd.isna(sim):
        return '无相似度'
    if sim >= 0.80:        # 强相关阈值
        return '强相关'
    elif sim >= 0.65:      # 较相关阈值
        return '较相关'
    elif sim >= 0.5:       # 弱相关阈值
        return '弱相关'
    else:
        return '不相关'
```

## 高级功能

### 批量处理大数据

对于超过10万条记录的数据，建议使用批处理模式：

1. **准备数据**：将数据放入 `input/batches_auto/` 目录
2. **运行批处理**：
   ```bash
   python main_auto_batch.py
   ```
3. **监控进度**：查看 `auto_batch_processing.log` 文件

### 结果分析

使用 `analyze_similarity_result.py` 进行结果分析：

```bash
python analyze_similarity_result.py
```

这个脚本会：
- 自动找到最新的结果文件
- 添加相关性判断
- 生成优化建议
- 保存到新的分析文件

### 单元级别分析

使用 `analyze_unit_levels.py` 进行更详细的分析：

```bash
python analyze_unit_levels.py
```

## 输出结果说明

### 相似度分数

- **0.80-1.00**: 强相关 - 建议添加到账户
- **0.65-0.79**: 较相关 - 建议添加到账户
- **0.50-0.64**: 弱相关 - 需要人工判断
- **0.00-0.49**: 不相关 - 建议加入否词

### 优化建议

程序会根据相似度和账户状态自动生成建议：

| 相似度 | 账户状态 | 建议动作 |
|--------|----------|----------|
| 强相关/较相关 | 未添加 | 添加至账户内 |
| 弱相关 | 未添加 | 需人工判断处理 |
| 不相关 | 未添加 | 加入否词 |
| 任意 | 已添加 | 已添加，无需操作 |

### 结果文件字段

输出文件包含以下字段：
- `关键词/营销要点/知识问答`: 原始关键词
- `搜索词`: 原始搜索词
- `final_similarity`: 相似度分数
- `相关性判断（建议）`: 相关性等级
- `建议优化动作`: 具体操作建议
- `账户添加状态`: 当前账户状态

## 性能优化建议

### 1. 硬件配置

- **GPU模式**: 推荐16GB+显存，CUDA 11.0+
- **CPU模式**: 推荐16GB+内存，多核处理器
- **存储**: 推荐SSD，至少10GB可用空间

### 2. 参数调优

根据你的硬件调整以下参数：

```python
# 小内存设备 (8GB RAM)
BATCH_SIZE = 8
MAX_LENGTH = 64

# 中等内存设备 (16GB RAM)
BATCH_SIZE = 32
MAX_LENGTH = 128

# 大内存设备 (32GB+ RAM)
BATCH_SIZE = 64
MAX_LENGTH = 256
```

### 3. 缓存管理

定期清理缓存文件以释放空间：

```bash
python quick_clear_cache.py
```

## 常见使用场景

### 场景1：日常关键词优化

1. 准备包含新搜索词的数据文件
2. 运行 `python run_safe.py`
3. 查看结果，根据建议优化账户

### 场景2：大规模数据清理

1. 将大量数据分批放入 `input/batches_auto/`
2. 运行 `python main_auto_batch.py`
3. 等待处理完成，查看合并结果

### 场景3：定期账户审核

1. 导出当前账户数据
2. 运行相似度分析
3. 根据结果调整账户结构

### 场景4：竞品分析

1. 收集竞品关键词和搜索词
2. 运行相似度分析
3. 发现新的优化机会

## 故障排除

### 程序运行缓慢

**可能原因**：
- 批次大小过大
- 内存不足
- GPU驱动问题

**解决方法**：
```bash
# 减少批次大小
python main_cpu.py  # 使用CPU模式

# 或调整配置
export BATCH_SIZE=8
```

### 内存不足错误

**可能原因**：
- 数据量过大
- 批次大小过大
- 系统内存不足

**解决方法**：
```bash
# 使用超安全模式
python run_ultra_safe.py

# 或分批处理
python main_auto_batch.py
```

### 模型加载失败

**可能原因**：
- 网络连接问题
- 磁盘空间不足
- 模型文件损坏

**解决方法**：
1. 检查网络连接
2. 清理磁盘空间
3. 重新下载模型文件

## 最佳实践

### 1. 数据准备
- 确保数据格式正确
- 清理无效数据
- 分批处理大数据

### 2. 运行策略
- 首次使用选择安全模式
- 根据结果调整参数
- 定期清理缓存文件

### 3. 结果应用
- 结合业务逻辑判断
- 定期回顾和优化
- 记录优化效果

### 4. 性能监控
- 关注内存使用情况
- 监控处理速度
- 及时调整配置

## 下一步

- [配置说明](配置说明.md) - 了解详细配置选项
- [故障排除](故障排除.md) - 解决常见问题
- [API文档](API文档.md) - 了解程序接口
- [贡献指南](贡献指南.md) - 参与项目开发
